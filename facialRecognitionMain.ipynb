{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "493cb513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis is the code that will be used to train our model to recpgnize the emotion on faces.\\n\\nWe will be utilizing Keras as the main package to train the Deep Learning model.\\nThe emotions that will be fed into the model and that it can recognize are:\\n - Angry\\n - Disgust\\n - Fear\\n - Happy\\n - Neutral\\n - Sad\\n - Surprise\\n\\nThe Keggle dataset is used to train the deep learning model for emotion recognition. The name of the data set is\\nFace expression recognition dataset.\\nLINK - https://www.kaggle.com/datasets/jonathanoheix/face-expression-recognition-dataset\\n\\nThe accuracy was plotted at the end of the file.\\nAn avergae accuracy of XYZ is recorded for this model\\n\\nSources & Research\\n - https://www.youtube.com/watch?v=Bb4Wvl57LIk\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is the code that will be used to train our model to recpgnize the emotion on faces.\n",
    "\n",
    "We will be utilizing Keras as the main package to train the Deep Learning model.\n",
    "The emotions that will be fed into the model and that it can recognize are:\n",
    " - Angry\n",
    " - Disgust\n",
    " - Fear\n",
    " - Happy\n",
    " - Neutral\n",
    " - Sad\n",
    " - Surprise\n",
    "\n",
    "The Keggle dataset is used to train the deep learning model for emotion recognition. The name of the data set is\n",
    "Face expression recognition dataset.\n",
    "LINK - https://www.kaggle.com/datasets/jonathanoheix/face-expression-recognition-dataset\n",
    "\n",
    "The accuracy was plotted at the end of the file.\n",
    "An avergae accuracy of XYZ is recorded for this model\n",
    "\n",
    "Sources & Research\n",
    " - https://www.youtube.com/watch?v=Bb4Wvl57LIk\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80a9b64",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b1191d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python==3.4.2.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8b0b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df6ec2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 00:41:44.597636: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.7.8)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from time import sleep\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import Project\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "from pygame import mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9b8f80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_playlist(folder):\n",
    "    playlist = []\n",
    "    for filename in os.listdir(\"Project/\"+folder):\n",
    "\t    playlist.append(filename)\n",
    "\n",
    "    print(playlist[0:])\n",
    "    return playlist\n",
    "\n",
    "\n",
    "def play_music(playlist):\n",
    "    mixer.init()\n",
    "  \n",
    "    # Loading the song\n",
    "    mixer.music.load(playlist[0])\n",
    "    \n",
    "    # Setting the volume\n",
    "    mixer.music.set_volume(0.7)\n",
    "    \n",
    "    # Start playing the song\n",
    "    mixer.music.play()\n",
    "    i = 0\n",
    "    # infinite loop\n",
    "    while True:\n",
    "        \n",
    "        print(\"Press 'p' to pause, 'r' to resume\")\n",
    "        print(\"Press 'n' to play the next song\")\n",
    "        print(\"Press 'e' to exit the program\")\n",
    "        \n",
    "        query = input(\"  \")\n",
    "        \n",
    "        if query == 'p':\n",
    "    \n",
    "            # Pausing the music\n",
    "            mixer.music.pause()     \n",
    "        elif query == 'r':\n",
    "    \n",
    "            # Resuming the music\n",
    "            mixer.music.unpause()\n",
    "            \n",
    "        elif query == 'n':\n",
    "            i = i + 1\n",
    "            if i != len(playlist):\n",
    "                print(len(playlist))\n",
    "                mixer.music.load(playlist[i])\n",
    "                mixer.music.play()\n",
    "            \n",
    "            else:\n",
    "                mixer.music.stop()\n",
    "                print(\"That's all the music I have for today. Try again later.\")\n",
    "                break\n",
    "                \n",
    "        elif query == 'e':\n",
    "    \n",
    "            # Stop the mixer\n",
    "            mixer.music.stop()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8166240e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 00:41:54.593077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + './haarcascade_frontalface_default.xml')\n",
    "classifier =load_model('model.h5')\n",
    "\n",
    "emotion_labels = ['Angry','Disgust','Fear','Happy','Neutral', 'Sad', 'Surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9310b276",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 90)\n",
    "    labels = []\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi_gray = gray[y:y+h,x:x+w]\n",
    "        roi_gray = cv2.resize(roi_gray,(48,48),interpolation=cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "\n",
    "        if np.sum([roi_gray])!=0:\n",
    "            roi = roi_gray.astype('float')/255.0\n",
    "            roi = img_to_array(roi)\n",
    "            roi = np.expand_dims(roi,axis=0)\n",
    "\n",
    "            prediction = classifier.predict(roi)[0]\n",
    "            label=emotion_labels[prediction.argmax()]\n",
    "            label_position = (x,y)\n",
    "            cv2.putText(frame,label,label_position,cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "        else:\n",
    "            cv2.putText(frame,'No Faces',(30,80),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "    cv2.imshow('Emotion Detector',frame)\n",
    "    if cv2.waitKey(1) or 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47ff7089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['You Rock My World.wav', 'Tems - Higher(Lyrics Video).wav', 'novocane by frank ocean clean.wav', '[CLEAN] Tyler, The Creator - WUSYANAME (feat. YoungBoy Never Broke Again & Ty Dolla $ign).wav']\n",
      "Press 'p' to pause, 'r' to resume\n",
      "Press 'n' to play the next song\n",
      "Press 'e' to exit the program\n",
      "  p\n",
      "Press 'p' to pause, 'r' to resume\n",
      "Press 'n' to play the next song\n",
      "Press 'e' to exit the program\n",
      "  r\n",
      "Press 'p' to pause, 'r' to resume\n",
      "Press 'n' to play the next song\n",
      "Press 'e' to exit the program\n",
      "  n\n",
      "4\n",
      "Press 'p' to pause, 'r' to resume\n",
      "Press 'n' to play the next song\n",
      "Press 'e' to exit the program\n",
      "  e\n"
     ]
    }
   ],
   "source": [
    "playlist = make_playlist(label)\n",
    "play_music(playlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba306179",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
